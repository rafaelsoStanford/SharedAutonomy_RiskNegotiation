{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaelsoStanford/SharedAutonomy_RiskNegotiation/blob/main/CarRacing_v2_DiffusionPolicy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tf3JP6vSyP4",
        "outputId": "0c6c6433-8892-454a-f40f-c258c6f1b467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.11\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Installing pip packages**\n",
        "#@markdown - Diffusion Model: [PyTorch](https://pytorch.org) & [HuggingFace diffusers](https://huggingface.co/docs/diffusers/index)\n",
        "#@markdown - Dataset Loading: [Zarr](https://zarr.readthedocs.io/en/stable/) & numcodecs\n",
        "#@markdown -  gym, pygame, pymunk & shapely\n",
        "!python --version\n",
        "!apt install swig &> /dev/null\n",
        "!pip3 uninstall cvxpy -y > /dev/null\n",
        "!pip3 install gymnasium[box2d] &> /dev/null\n",
        "!pip3 install torch==1.13.1 torchvision==0.14.1 diffusers==0.11.1 \\\n",
        "scikit-image==0.19.3 scikit-video==1.1.11 zarr==2.12.0 numcodecs==0.10.2 \\\n",
        "&> /dev/null # mute output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQYoewg0I-PG",
        "outputId": "a443a2b3-c29d-42b1-bbcf-acdc6d16a74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "yflI2ihsS81P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbdb7ef9-2685-4418-ad9d-a830f8036cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.1.3 (SDL 2.0.22, Python 3.10.11)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Imports**\n",
        "# Diffusion policy import\n",
        "from typing import Tuple, Sequence, Dict, Union, Optional, Callable\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import collections\n",
        "import zarr\n",
        "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
        "from diffusers.training_utils import EMAModel\n",
        "from diffusers.optimization import get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# env imports\n",
        "import pygame\n",
        "from pygame import gfxdraw\n",
        "\n",
        "import shapely.geometry as sg\n",
        "import cv2\n",
        "import skimage.transform as st\n",
        "from skvideo.io import vwrite\n",
        "from IPython.display import Video\n",
        "import gdown\n",
        "import os\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from gymnasium.envs.box2d.car_dynamics import Car\n",
        "from gymnasium.error import DependencyNotInstalled, InvalidAction\n",
        "from gymnasium.utils import EzPickle\n",
        "from typing import Optional, Union\n",
        "\n",
        "import Box2D\n",
        "from Box2D.b2 import fixtureDef\n",
        "from Box2D.b2 import polygonShape\n",
        "from Box2D.b2 import contactListener\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "uqD7R97wV0mP"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Environment**\n",
        "#@markdown Slightly modified version of the CarRacing Environment \"CarRacing-v2\".\n",
        "#@markdown Adapted from [Gymnasium](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/box2d/car_racing.py)\n",
        "#@markdown - Added new functions which return `velocity` and `on_track_flag` of the car\n",
        "#@markdown - Observations are now returned as a dictionary and then accessed as needed in subsequent cells\n",
        "\n",
        "__credits__ = [\"Andrea PIERRÃ‰\"]\n",
        "\n",
        "\n",
        "STATE_W = 96  # less than Atari 160x192\n",
        "STATE_H = 96\n",
        "VIDEO_W = 600\n",
        "VIDEO_H = 400\n",
        "WINDOW_W = 1000\n",
        "WINDOW_H = 800\n",
        "\n",
        "SCALE = 6.0  # Track scale\n",
        "TRACK_RAD = 900 / SCALE  # Track is heavily morphed circle with this radius\n",
        "PLAYFIELD = 2000 / SCALE  # Game over boundary\n",
        "FPS = 50  # Frames per second\n",
        "ZOOM = 2.7  # Camera zoom\n",
        "ZOOM_FOLLOW = True  # Set to False for fixed view (don't use zoom)\n",
        "\n",
        "\n",
        "TRACK_DETAIL_STEP = 21 / SCALE\n",
        "TRACK_TURN_RATE = 0.31\n",
        "TRACK_WIDTH = 40 / SCALE\n",
        "BORDER = 8 / SCALE\n",
        "BORDER_MIN_COUNT = 4\n",
        "GRASS_DIM = PLAYFIELD / 20.0\n",
        "MAX_SHAPE_DIM = (\n",
        "    max(GRASS_DIM, TRACK_WIDTH, TRACK_DETAIL_STEP) * math.sqrt(2) * ZOOM * SCALE\n",
        ")\n",
        "\n",
        "\n",
        "class FrictionDetector(contactListener):\n",
        "    def __init__(self, env, lap_complete_percent):\n",
        "        contactListener.__init__(self)\n",
        "        self.env = env\n",
        "        self.lap_complete_percent = lap_complete_percent\n",
        "\n",
        "    def BeginContact(self, contact):\n",
        "        self._contact(contact, True)\n",
        "\n",
        "    def EndContact(self, contact):\n",
        "        self._contact(contact, False)\n",
        "\n",
        "    def _contact(self, contact, begin):\n",
        "        tile = None\n",
        "        obj = None\n",
        "        u1 = contact.fixtureA.body.userData\n",
        "        u2 = contact.fixtureB.body.userData\n",
        "        if u1 and \"road_friction\" in u1.__dict__:\n",
        "            tile = u1\n",
        "            obj = u2\n",
        "        if u2 and \"road_friction\" in u2.__dict__:\n",
        "            tile = u2\n",
        "            obj = u1\n",
        "        if not tile:\n",
        "            return\n",
        "\n",
        "        # inherit tile color from env\n",
        "        tile.color[:] = self.env.road_color\n",
        "        if not obj or \"tiles\" not in obj.__dict__:\n",
        "            return\n",
        "        if begin:\n",
        "            obj.tiles.add(tile)\n",
        "            if not tile.road_visited:\n",
        "                tile.road_visited = True\n",
        "                self.env.reward += 1000.0 / len(self.env.track)\n",
        "                self.env.tile_visited_count += 1\n",
        "\n",
        "                # Lap is considered completed if enough % of the track was covered\n",
        "                if (\n",
        "                    tile.idx == 0\n",
        "                    and self.env.tile_visited_count / len(self.env.track)\n",
        "                    > self.lap_complete_percent\n",
        "                ):\n",
        "                    self.env.new_lap = True\n",
        "        else:\n",
        "            obj.tiles.remove(tile)\n",
        "\n",
        "\n",
        "class CarRacing(gym.Env, EzPickle):\n",
        "    \"\"\"\n",
        "    ## Description\n",
        "    The easiest control task to learn from pixels - a top-down\n",
        "    racing environment. The generated track is random every episode.\n",
        "\n",
        "    Some indicators are shown at the bottom of the window along with the\n",
        "    state RGB buffer. From left to right: true speed, four ABS sensors,\n",
        "    steering wheel position, and gyroscope.\n",
        "    To play yourself (it's rather fast for humans), type:\n",
        "    ```\n",
        "    python gymnasium/envs/box2d/car_racing.py\n",
        "    ```\n",
        "    Remember: it's a powerful rear-wheel drive car - don't press the accelerator\n",
        "    and turn at the same time.\n",
        "\n",
        "    ## Action Space\n",
        "    If continuous there are 3 actions :\n",
        "    - 0: steering, -1 is full left, +1 is full right\n",
        "    - 1: gas\n",
        "    - 2: breaking\n",
        "\n",
        "    If discrete there are 5 actions:\n",
        "    - 0: do nothing\n",
        "    - 1: steer left\n",
        "    - 2: steer right\n",
        "    - 3: gas\n",
        "    - 4: brake\n",
        "\n",
        "    ## Observation Space\n",
        "\n",
        "    A top-down 96x96 RGB image of the car and race track.\n",
        "\n",
        "    ## Rewards\n",
        "    The reward is -0.1 every frame and +1000/N for every track tile visited,\n",
        "    where N is the total number of tiles visited in the track. For example,\n",
        "    if you have finished in 732 frames, your reward is\n",
        "    1000 - 0.1*732 = 926.8 points.\n",
        "\n",
        "    ## Starting State\n",
        "    The car starts at rest in the center of the road.\n",
        "\n",
        "    ## Episode Termination\n",
        "    The episode finishes when all the tiles are visited. The car can also go\n",
        "    outside the playfield - that is, far off the track, in which case it will\n",
        "    receive -100 reward and die.\n",
        "\n",
        "    ## Arguments\n",
        "    `lap_complete_percent` dictates the percentage of tiles that must be visited by\n",
        "    the agent before a lap is considered complete.\n",
        "\n",
        "    Passing `domain_randomize=True` enables the domain randomized variant of the environment.\n",
        "    In this scenario, the background and track colours are different on every reset.\n",
        "\n",
        "    Passing `continuous=False` converts the environment to use discrete action space.\n",
        "    The discrete action space has 5 actions: [do nothing, left, right, gas, brake].\n",
        "\n",
        "    ## Reset Arguments\n",
        "    Passing the option `options[\"randomize\"] = True` will change the current colour of the environment on demand.\n",
        "    Correspondingly, passing the option `options[\"randomize\"] = False` will not change the current colour of the environment.\n",
        "    `domain_randomize` must be `True` on init for this argument to work.\n",
        "    Example usage:\n",
        "    ```python\n",
        "    import gymnasium as gym\n",
        "    env = gym.make(\"CarRacing-v1\", domain_randomize=True)\n",
        "\n",
        "    # normal reset, this changes the colour scheme by default\n",
        "    env.reset()\n",
        "\n",
        "    # reset with colour scheme change\n",
        "    env.reset(options={\"randomize\": True})\n",
        "\n",
        "    # reset with no colour scheme change\n",
        "    env.reset(options={\"randomize\": False})\n",
        "    ```\n",
        "\n",
        "    ## Version History\n",
        "    - v1: Change track completion logic and add domain randomization (0.24.0)\n",
        "    - v0: Original version\n",
        "\n",
        "    ## References\n",
        "    - Chris Campbell (2014), http://www.iforce2d.net/b2dtut/top-down-car.\n",
        "\n",
        "    ## Credits\n",
        "    Created by Oleg Klimov\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {\n",
        "        \"render_modes\": [\n",
        "            \"human\",\n",
        "            \"rgb_array\",\n",
        "            \"state_pixels\",\n",
        "        ],\n",
        "        \"render_fps\": FPS,\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        render_mode: Optional[str] = None,\n",
        "        verbose: bool = False,\n",
        "        lap_complete_percent: float = 0.95,\n",
        "        domain_randomize: bool = False,\n",
        "        continuous: bool = True,\n",
        "    ):\n",
        "        EzPickle.__init__(\n",
        "            self,\n",
        "            render_mode,\n",
        "            verbose,\n",
        "            lap_complete_percent,\n",
        "            domain_randomize,\n",
        "            continuous,\n",
        "        )\n",
        "        self.continuous = continuous\n",
        "        self.domain_randomize = domain_randomize\n",
        "        self.lap_complete_percent = lap_complete_percent\n",
        "        self._init_colors()\n",
        "\n",
        "        self.contactListener_keepref = FrictionDetector(self, self.lap_complete_percent)\n",
        "        self.world = Box2D.b2World((0, 0), contactListener=self.contactListener_keepref)\n",
        "        self.screen: Optional[pygame.Surface] = None\n",
        "        self.surf = None\n",
        "        self.clock = None\n",
        "        self.isopen = True\n",
        "        self.invisible_state_window = None\n",
        "        self.invisible_video_window = None\n",
        "        self.road = None\n",
        "        self.car: Optional[Car] = None\n",
        "        self.reward = 0.0\n",
        "        self.prev_reward = 0.0\n",
        "        self.verbose = verbose\n",
        "        self.new_lap = False\n",
        "        self.fd_tile = fixtureDef(\n",
        "            shape=polygonShape(vertices=[(0, 0), (1, 0), (1, -1), (0, -1)])\n",
        "        )\n",
        "\n",
        "        # This will throw a warning in tests/envs/test_envs in utils/env_checker.py as the space is not symmetric\n",
        "        #   or normalised however this is not possible here so ignore\n",
        "        if self.continuous:\n",
        "            self.action_space = spaces.Box(\n",
        "                np.array([-1, 0, 0]).astype(np.float32),\n",
        "                np.array([+1, +1, +1]).astype(np.float32),\n",
        "            )  # steer, gas, brake\n",
        "        else:\n",
        "            self.action_space = spaces.Discrete(5)\n",
        "            # do nothing, left, right, gas, brake\n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0, high=255, shape=(STATE_H, STATE_W, 3), dtype=np.uint8\n",
        "        )\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "\n",
        "    def _destroy(self):\n",
        "        if not self.road:\n",
        "            return\n",
        "        for t in self.road:\n",
        "            self.world.DestroyBody(t)\n",
        "        self.road = []\n",
        "        assert self.car is not None\n",
        "        self.car.destroy()\n",
        "\n",
        "    def _init_colors(self):\n",
        "        if self.domain_randomize:\n",
        "            # domain randomize the bg and grass colour\n",
        "            self.road_color = self.np_random.uniform(0, 210, size=3)\n",
        "\n",
        "            self.bg_color = self.np_random.uniform(0, 210, size=3)\n",
        "\n",
        "            self.grass_color = np.copy(self.bg_color)\n",
        "            idx = self.np_random.integers(3)\n",
        "            self.grass_color[idx] += 20\n",
        "        else:\n",
        "            # default colours\n",
        "            self.road_color = np.array([102, 102, 102])\n",
        "            self.bg_color = np.array([102, 204, 102])\n",
        "            self.grass_color = np.array([102, 230, 102])\n",
        "\n",
        "    def _reinit_colors(self, randomize):\n",
        "        assert (\n",
        "            self.domain_randomize\n",
        "        ), \"domain_randomize must be True to use this function.\"\n",
        "\n",
        "        if randomize:\n",
        "            # domain randomize the bg and grass colour\n",
        "            self.road_color = self.np_random.uniform(0, 210, size=3)\n",
        "\n",
        "            self.bg_color = self.np_random.uniform(0, 210, size=3)\n",
        "\n",
        "            self.grass_color = np.copy(self.bg_color)\n",
        "            idx = self.np_random.integers(3)\n",
        "            self.grass_color[idx] += 20\n",
        "\n",
        "    def _create_track(self):\n",
        "        CHECKPOINTS = 12\n",
        "\n",
        "        # Create checkpoints\n",
        "        checkpoints = []\n",
        "        for c in range(CHECKPOINTS):\n",
        "            noise = self.np_random.uniform(0, 2 * math.pi * 1 / CHECKPOINTS)\n",
        "            alpha = 2 * math.pi * c / CHECKPOINTS + noise\n",
        "            rad = self.np_random.uniform(TRACK_RAD / 3, TRACK_RAD)\n",
        "\n",
        "            if c == 0:\n",
        "                alpha = 0\n",
        "                rad = 1.5 * TRACK_RAD\n",
        "            if c == CHECKPOINTS - 1:\n",
        "                alpha = 2 * math.pi * c / CHECKPOINTS\n",
        "                self.start_alpha = 2 * math.pi * (-0.5) / CHECKPOINTS\n",
        "                rad = 1.5 * TRACK_RAD\n",
        "\n",
        "            checkpoints.append((alpha, rad * math.cos(alpha), rad * math.sin(alpha)))\n",
        "        self.road = []\n",
        "\n",
        "        # Go from one checkpoint to another to create track\n",
        "        x, y, beta = 1.5 * TRACK_RAD, 0, 0\n",
        "        dest_i = 0\n",
        "        laps = 0\n",
        "        track = []\n",
        "        no_freeze = 2500\n",
        "        visited_other_side = False\n",
        "        while True:\n",
        "            alpha = math.atan2(y, x)\n",
        "            if visited_other_side and alpha > 0:\n",
        "                laps += 1\n",
        "                visited_other_side = False\n",
        "            if alpha < 0:\n",
        "                visited_other_side = True\n",
        "                alpha += 2 * math.pi\n",
        "\n",
        "            while True:  # Find destination from checkpoints\n",
        "                failed = True\n",
        "\n",
        "                while True:\n",
        "                    dest_alpha, dest_x, dest_y = checkpoints[dest_i % len(checkpoints)]\n",
        "                    if alpha <= dest_alpha:\n",
        "                        failed = False\n",
        "                        break\n",
        "                    dest_i += 1\n",
        "                    if dest_i % len(checkpoints) == 0:\n",
        "                        break\n",
        "\n",
        "                if not failed:\n",
        "                    break\n",
        "\n",
        "                alpha -= 2 * math.pi\n",
        "                continue\n",
        "\n",
        "            r1x = math.cos(beta)\n",
        "            r1y = math.sin(beta)\n",
        "            p1x = -r1y\n",
        "            p1y = r1x\n",
        "            dest_dx = dest_x - x  # vector towards destination\n",
        "            dest_dy = dest_y - y\n",
        "            # destination vector projected on rad:\n",
        "            proj = r1x * dest_dx + r1y * dest_dy\n",
        "            while beta - alpha > 1.5 * math.pi:\n",
        "                beta -= 2 * math.pi\n",
        "            while beta - alpha < -1.5 * math.pi:\n",
        "                beta += 2 * math.pi\n",
        "            prev_beta = beta\n",
        "            proj *= SCALE\n",
        "            if proj > 0.3:\n",
        "                beta -= min(TRACK_TURN_RATE, abs(0.001 * proj))\n",
        "            if proj < -0.3:\n",
        "                beta += min(TRACK_TURN_RATE, abs(0.001 * proj))\n",
        "            x += p1x * TRACK_DETAIL_STEP\n",
        "            y += p1y * TRACK_DETAIL_STEP\n",
        "            track.append((alpha, prev_beta * 0.5 + beta * 0.5, x, y))\n",
        "            if laps > 4:\n",
        "                break\n",
        "            no_freeze -= 1\n",
        "            if no_freeze == 0:\n",
        "                break\n",
        "\n",
        "        # Find closed loop range i1..i2, first loop should be ignored, second is OK\n",
        "        i1, i2 = -1, -1\n",
        "        i = len(track)\n",
        "        while True:\n",
        "            i -= 1\n",
        "            if i == 0:\n",
        "                return False  # Failed\n",
        "            pass_through_start = (\n",
        "                track[i][0] > self.start_alpha and track[i - 1][0] <= self.start_alpha\n",
        "            )\n",
        "            if pass_through_start and i2 == -1:\n",
        "                i2 = i\n",
        "            elif pass_through_start and i1 == -1:\n",
        "                i1 = i\n",
        "                break\n",
        "        if self.verbose:\n",
        "            print(\"Track generation: %i..%i -> %i-tiles track\" % (i1, i2, i2 - i1))\n",
        "        assert i1 != -1\n",
        "        assert i2 != -1\n",
        "\n",
        "        track = track[i1 : i2 - 1]\n",
        "\n",
        "        first_beta = track[0][1]\n",
        "        first_perp_x = math.cos(first_beta)\n",
        "        first_perp_y = math.sin(first_beta)\n",
        "        # Length of perpendicular jump to put together head and tail\n",
        "        well_glued_together = np.sqrt(\n",
        "            np.square(first_perp_x * (track[0][2] - track[-1][2]))\n",
        "            + np.square(first_perp_y * (track[0][3] - track[-1][3]))\n",
        "        )\n",
        "        if well_glued_together > TRACK_DETAIL_STEP:\n",
        "            return False\n",
        "\n",
        "        # Red-white border on hard turns\n",
        "        border = [False] * len(track)\n",
        "        for i in range(len(track)):\n",
        "            good = True\n",
        "            oneside = 0\n",
        "            for neg in range(BORDER_MIN_COUNT):\n",
        "                beta1 = track[i - neg - 0][1]\n",
        "                beta2 = track[i - neg - 1][1]\n",
        "                good &= abs(beta1 - beta2) > TRACK_TURN_RATE * 0.2\n",
        "                oneside += np.sign(beta1 - beta2)\n",
        "            good &= abs(oneside) == BORDER_MIN_COUNT\n",
        "            border[i] = good\n",
        "        for i in range(len(track)):\n",
        "            for neg in range(BORDER_MIN_COUNT):\n",
        "                border[i - neg] |= border[i]\n",
        "\n",
        "        # Create tiles\n",
        "        for i in range(len(track)):\n",
        "            alpha1, beta1, x1, y1 = track[i]\n",
        "            alpha2, beta2, x2, y2 = track[i - 1]\n",
        "            road1_l = (\n",
        "                x1 - TRACK_WIDTH * math.cos(beta1),\n",
        "                y1 - TRACK_WIDTH * math.sin(beta1),\n",
        "            )\n",
        "            road1_r = (\n",
        "                x1 + TRACK_WIDTH * math.cos(beta1),\n",
        "                y1 + TRACK_WIDTH * math.sin(beta1),\n",
        "            )\n",
        "            road2_l = (\n",
        "                x2 - TRACK_WIDTH * math.cos(beta2),\n",
        "                y2 - TRACK_WIDTH * math.sin(beta2),\n",
        "            )\n",
        "            road2_r = (\n",
        "                x2 + TRACK_WIDTH * math.cos(beta2),\n",
        "                y2 + TRACK_WIDTH * math.sin(beta2),\n",
        "            )\n",
        "            vertices = [road1_l, road1_r, road2_r, road2_l]\n",
        "            self.fd_tile.shape.vertices = vertices\n",
        "            t = self.world.CreateStaticBody(fixtures=self.fd_tile)\n",
        "            t.userData = t\n",
        "            c = 0.01 * (i % 3) * 255\n",
        "            t.color = self.road_color + c\n",
        "            t.road_visited = False\n",
        "            t.road_friction = 1.0\n",
        "            t.idx = i\n",
        "            t.fixtures[0].sensor = True\n",
        "            self.road_poly.append(([road1_l, road1_r, road2_r, road2_l], t.color))\n",
        "            self.road.append(t)\n",
        "            if border[i]:\n",
        "                side = np.sign(beta2 - beta1)\n",
        "                b1_l = (\n",
        "                    x1 + side * TRACK_WIDTH * math.cos(beta1),\n",
        "                    y1 + side * TRACK_WIDTH * math.sin(beta1),\n",
        "                )\n",
        "                b1_r = (\n",
        "                    x1 + side * (TRACK_WIDTH + BORDER) * math.cos(beta1),\n",
        "                    y1 + side * (TRACK_WIDTH + BORDER) * math.sin(beta1),\n",
        "                )\n",
        "                b2_l = (\n",
        "                    x2 + side * TRACK_WIDTH * math.cos(beta2),\n",
        "                    y2 + side * TRACK_WIDTH * math.sin(beta2),\n",
        "                )\n",
        "                b2_r = (\n",
        "                    x2 + side * (TRACK_WIDTH + BORDER) * math.cos(beta2),\n",
        "                    y2 + side * (TRACK_WIDTH + BORDER) * math.sin(beta2),\n",
        "                )\n",
        "                self.road_poly.append(\n",
        "                    (\n",
        "                        [b1_l, b1_r, b2_r, b2_l],\n",
        "                        (255, 255, 255) if i % 2 == 0 else (255, 0, 0),\n",
        "                    )\n",
        "                )\n",
        "        self.track = track\n",
        "        return True\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        *,\n",
        "        seed: Optional[int] = None,\n",
        "        options: Optional[dict] = None,\n",
        "    ):\n",
        "        super().reset(seed=seed)\n",
        "        self._destroy()\n",
        "        self.world.contactListener_bug_workaround = FrictionDetector(\n",
        "            self, self.lap_complete_percent\n",
        "        )\n",
        "        self.world.contactListener = self.world.contactListener_bug_workaround\n",
        "        self.reward = 0.0\n",
        "        self.prev_reward = 0.0\n",
        "        self.tile_visited_count = 0\n",
        "        self.t = 0.0\n",
        "        self.new_lap = False\n",
        "        self.road_poly = []\n",
        "\n",
        "        if self.domain_randomize:\n",
        "            randomize = True\n",
        "            if isinstance(options, dict):\n",
        "                if \"randomize\" in options:\n",
        "                    randomize = options[\"randomize\"]\n",
        "\n",
        "            self._reinit_colors(randomize)\n",
        "\n",
        "        while True:\n",
        "            success = self._create_track()\n",
        "            if success:\n",
        "                break\n",
        "            if self.verbose:\n",
        "                print(\n",
        "                    \"retry to generate track (normal if there are not many\"\n",
        "                    \"instances of this message)\"\n",
        "                )\n",
        "        self.car = Car(self.world, *self.track[0][1:4])\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self.render()\n",
        "        return self.step(None)[0], {}\n",
        "\n",
        "    def return_velocity(self):\n",
        "        return self.car.hull.linearVelocity\n",
        "\n",
        "    def return_abs_velocity(self):\n",
        "        v= self.car.hull.linearVelocity\n",
        "        return np.linalg.norm(v)\n",
        "\n",
        "    def return_track_flag(self):\n",
        "        \"\"\"\n",
        "        Verify if a tire is on grass tile\n",
        "        Returns: True if on track, False if on grass\n",
        "        \"\"\"\n",
        "        grass = True\n",
        "        track = False\n",
        "        for w in self.car.wheels:\n",
        "            for tile in w.tiles:\n",
        "                #If there is a tile that is not grass, then the car is not on grass\n",
        "                grass = False  \n",
        "                track = True \n",
        "        return track\n",
        "\n",
        "    def step(self, action: Union[np.ndarray, int]):\n",
        "        assert self.car is not None\n",
        "        if action is not None:\n",
        "            if self.continuous:\n",
        "                self.car.steer(-action[0])\n",
        "                self.car.gas(action[1])\n",
        "                self.car.brake(action[2])\n",
        "            else:\n",
        "                if not self.action_space.contains(action):\n",
        "                    raise InvalidAction(\n",
        "                        f\"you passed the invalid action `{action}`. \"\n",
        "                        f\"The supported action_space is `{self.action_space}`\"\n",
        "                    )\n",
        "                self.car.steer(-0.6 * (action == 1) + 0.6 * (action == 2))\n",
        "                self.car.gas(0.2 * (action == 3))\n",
        "                self.car.brake(0.8 * (action == 4))\n",
        "\n",
        "        self.car.step(1.0 / FPS)\n",
        "        self.world.Step(1.0 / FPS, 6 * 30, 2 * 30)\n",
        "        self.t += 1.0 / FPS\n",
        "\n",
        "        self.state = self._render(\"state_pixels\")\n",
        "\n",
        "        step_reward = 0\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        if action is not None:  # First step without action, called from reset()\n",
        "            self.reward -= 0.1\n",
        "            # We actually don't want to count fuel spent, we want car to be faster.\n",
        "            # self.reward -=  10 * self.car.fuel_spent / ENGINE_POWER\n",
        "            self.car.fuel_spent = 0.0\n",
        "            step_reward = self.reward - self.prev_reward\n",
        "            self.prev_reward = self.reward\n",
        "            if self.tile_visited_count == len(self.track) or self.new_lap:\n",
        "                # Truncation due to finishing lap\n",
        "                # This should not be treated as a failure\n",
        "                # but like a timeout\n",
        "                truncated = True\n",
        "            x, y = self.car.hull.position\n",
        "            if abs(x) > PLAYFIELD or abs(y) > PLAYFIELD:\n",
        "                terminated = True\n",
        "                step_reward = -100\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self.render()\n",
        "        \n",
        "\n",
        "        # create observation dict\n",
        "        observation = {\n",
        "            \"image\": self.state,\n",
        "            \"velocity\": self.return_abs_velocity(),\n",
        "            \"on_track\": self.return_track_flag()\n",
        "        }\n",
        "        \n",
        "        #if action is None:\n",
        "        #  return self.state, step_reward, terminated, truncated, {}\n",
        "        return observation, step_reward, terminated, truncated, {}\n",
        "\n",
        "    def render(self):\n",
        "        if self.render_mode is None:\n",
        "            assert self.spec is not None\n",
        "            gym.logger.warn(\n",
        "                \"You are calling render method without specifying any render mode. \"\n",
        "                \"You can specify the render_mode at initialization, \"\n",
        "                f'e.g. gym.make(\"{self.spec.id}\", render_mode=\"rgb_array\")'\n",
        "            )\n",
        "            return\n",
        "        else:\n",
        "            return self._render(self.render_mode)\n",
        "\n",
        "    def _render(self, mode: str):\n",
        "        assert mode in self.metadata[\"render_modes\"]\n",
        "\n",
        "        pygame.font.init()\n",
        "        if self.screen is None and mode == \"human\":\n",
        "            pygame.init()\n",
        "            pygame.display.init()\n",
        "            self.screen = pygame.display.set_mode((WINDOW_W, WINDOW_H))\n",
        "        if self.clock is None:\n",
        "            self.clock = pygame.time.Clock()\n",
        "\n",
        "        if \"t\" not in self.__dict__:\n",
        "            return  # reset() not called yet\n",
        "\n",
        "        self.surf = pygame.Surface((WINDOW_W, WINDOW_H))\n",
        "\n",
        "        assert self.car is not None\n",
        "        # computing transformations\n",
        "        angle = -self.car.hull.angle\n",
        "        # Animating first second zoom.\n",
        "        zoom = 0.1 * SCALE * max(1 - self.t, 0) + ZOOM * SCALE * min(self.t, 1)\n",
        "        scroll_x = -(self.car.hull.position[0]) * zoom\n",
        "        scroll_y = -(self.car.hull.position[1]) * zoom\n",
        "        trans = pygame.math.Vector2((scroll_x, scroll_y)).rotate_rad(angle)\n",
        "        trans = (WINDOW_W / 2 + trans[0], WINDOW_H / 4 + trans[1])\n",
        "\n",
        "        self._render_road(zoom, trans, angle)\n",
        "        self.car.draw(\n",
        "            self.surf,\n",
        "            zoom,\n",
        "            trans,\n",
        "            angle,\n",
        "            mode not in [\"state_pixels_list\", \"state_pixels\"],\n",
        "        )\n",
        "\n",
        "        self.surf = pygame.transform.flip(self.surf, False, True)\n",
        "\n",
        "        # showing stats\n",
        "        self._render_indicators(WINDOW_W, WINDOW_H)\n",
        "\n",
        "        font = pygame.font.Font(pygame.font.get_default_font(), 42)\n",
        "        text = font.render(\"%04i\" % self.reward, True, (255, 255, 255), (0, 0, 0))\n",
        "        text_rect = text.get_rect()\n",
        "        text_rect.center = (60, WINDOW_H - WINDOW_H * 2.5 / 40.0)\n",
        "        self.surf.blit(text, text_rect)\n",
        "\n",
        "        if mode == \"human\":\n",
        "            pygame.event.pump()\n",
        "            self.clock.tick(self.metadata[\"render_fps\"])\n",
        "            assert self.screen is not None\n",
        "            self.screen.fill(0)\n",
        "            self.screen.blit(self.surf, (0, 0))\n",
        "            pygame.display.flip()\n",
        "        elif mode == \"rgb_array\":\n",
        "            return self._create_image_array(self.surf, (VIDEO_W, VIDEO_H))\n",
        "            \n",
        "        elif mode == \"state_pixels\":\n",
        "            return self._create_image_array(self.surf, (STATE_W, STATE_H))\n",
        "        else:\n",
        "            return self.isopen\n",
        "\n",
        "    def _render_road(self, zoom, translation, angle):\n",
        "        bounds = PLAYFIELD\n",
        "        field = [\n",
        "            (bounds, bounds),\n",
        "            (bounds, -bounds),\n",
        "            (-bounds, -bounds),\n",
        "            (-bounds, bounds),\n",
        "        ]\n",
        "\n",
        "        # draw background\n",
        "        self._draw_colored_polygon(\n",
        "            self.surf, field, self.bg_color, zoom, translation, angle, clip=False\n",
        "        )\n",
        "\n",
        "        # draw grass patches\n",
        "        grass = []\n",
        "        for x in range(-20, 20, 2):\n",
        "            for y in range(-20, 20, 2):\n",
        "                grass.append(\n",
        "                    [\n",
        "                        (GRASS_DIM * x + GRASS_DIM, GRASS_DIM * y + 0),\n",
        "                        (GRASS_DIM * x + 0, GRASS_DIM * y + 0),\n",
        "                        (GRASS_DIM * x + 0, GRASS_DIM * y + GRASS_DIM),\n",
        "                        (GRASS_DIM * x + GRASS_DIM, GRASS_DIM * y + GRASS_DIM),\n",
        "                    ]\n",
        "                )\n",
        "        for poly in grass:\n",
        "            self._draw_colored_polygon(\n",
        "                self.surf, poly, self.grass_color, zoom, translation, angle\n",
        "            )\n",
        "\n",
        "        # draw road\n",
        "        for poly, color in self.road_poly:\n",
        "            # converting to pixel coordinates\n",
        "            poly = [(p[0], p[1]) for p in poly]\n",
        "            color = [int(c) for c in color]\n",
        "            self._draw_colored_polygon(self.surf, poly, color, zoom, translation, angle)\n",
        "\n",
        "    def _render_indicators(self, W, H):\n",
        "        s = W / 40.0\n",
        "        h = H / 40.0\n",
        "        color = (0, 0, 0)\n",
        "        polygon = [(W, H), (W, H - 5 * h), (0, H - 5 * h), (0, H)]\n",
        "        pygame.draw.polygon(self.surf, color=color, points=polygon)\n",
        "\n",
        "        def vertical_ind(place, val):\n",
        "            return [\n",
        "                (place * s, H - (h + h * val)),\n",
        "                ((place + 1) * s, H - (h + h * val)),\n",
        "                ((place + 1) * s, H - h),\n",
        "                ((place + 0) * s, H - h),\n",
        "            ]\n",
        "\n",
        "        def horiz_ind(place, val):\n",
        "            return [\n",
        "                ((place + 0) * s, H - 4 * h),\n",
        "                ((place + val) * s, H - 4 * h),\n",
        "                ((place + val) * s, H - 2 * h),\n",
        "                ((place + 0) * s, H - 2 * h),\n",
        "            ]\n",
        "\n",
        "        assert self.car is not None\n",
        "        true_speed = np.sqrt(\n",
        "            np.square(self.car.hull.linearVelocity[0])\n",
        "            + np.square(self.car.hull.linearVelocity[1])\n",
        "        )\n",
        "\n",
        "        # simple wrapper to render if the indicator value is above a threshold\n",
        "        def render_if_min(value, points, color):\n",
        "            if abs(value) > 1e-4:\n",
        "                pygame.draw.polygon(self.surf, points=points, color=color)\n",
        "\n",
        "        render_if_min(true_speed, vertical_ind(5, 0.02 * true_speed), (255, 255, 255))\n",
        "        # ABS sensors\n",
        "        render_if_min(\n",
        "            self.car.wheels[0].omega,\n",
        "            vertical_ind(7, 0.01 * self.car.wheels[0].omega),\n",
        "            (0, 0, 255),\n",
        "        )\n",
        "        render_if_min(\n",
        "            self.car.wheels[1].omega,\n",
        "            vertical_ind(8, 0.01 * self.car.wheels[1].omega),\n",
        "            (0, 0, 255),\n",
        "        )\n",
        "        render_if_min(\n",
        "            self.car.wheels[2].omega,\n",
        "            vertical_ind(9, 0.01 * self.car.wheels[2].omega),\n",
        "            (51, 0, 255),\n",
        "        )\n",
        "        render_if_min(\n",
        "            self.car.wheels[3].omega,\n",
        "            vertical_ind(10, 0.01 * self.car.wheels[3].omega),\n",
        "            (51, 0, 255),\n",
        "        )\n",
        "\n",
        "        render_if_min(\n",
        "            self.car.wheels[0].joint.angle,\n",
        "            horiz_ind(20, -10.0 * self.car.wheels[0].joint.angle),\n",
        "            (0, 255, 0),\n",
        "        )\n",
        "        render_if_min(\n",
        "            self.car.hull.angularVelocity,\n",
        "            horiz_ind(30, -0.8 * self.car.hull.angularVelocity),\n",
        "            (255, 0, 0),\n",
        "        )\n",
        "\n",
        "    def _draw_colored_polygon(\n",
        "        self, surface, poly, color, zoom, translation, angle, clip=True\n",
        "    ):\n",
        "        poly = [pygame.math.Vector2(c).rotate_rad(angle) for c in poly]\n",
        "        poly = [\n",
        "            (c[0] * zoom + translation[0], c[1] * zoom + translation[1]) for c in poly\n",
        "        ]\n",
        "        # This checks if the polygon is out of bounds of the screen, and we skip drawing if so.\n",
        "        # Instead of calculating exactly if the polygon and screen overlap,\n",
        "        # we simply check if the polygon is in a larger bounding box whose dimension\n",
        "        # is greater than the screen by MAX_SHAPE_DIM, which is the maximum\n",
        "        # diagonal length of an environment object\n",
        "        if not clip or any(\n",
        "            (-MAX_SHAPE_DIM <= coord[0] <= WINDOW_W + MAX_SHAPE_DIM)\n",
        "            and (-MAX_SHAPE_DIM <= coord[1] <= WINDOW_H + MAX_SHAPE_DIM)\n",
        "            for coord in poly\n",
        "        ):\n",
        "            gfxdraw.aapolygon(self.surf, poly, color)\n",
        "            gfxdraw.filled_polygon(self.surf, poly, color)\n",
        "\n",
        "    def _create_image_array(self, screen, size):\n",
        "        scaled_screen = pygame.transform.smoothscale(screen, size)\n",
        "        return np.transpose(\n",
        "            np.array(pygame.surfarray.pixels3d(scaled_screen)), axes=(1, 0, 2)\n",
        "        )\n",
        "\n",
        "    def close(self):\n",
        "        if self.screen is not None:\n",
        "            pygame.display.quit()\n",
        "            self.isopen = False\n",
        "            pygame.quit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyUiDbc5WzpE",
        "outputId": "2f651774-efd2-4f08-fcf5-0379622ab7dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obs['image'].shape: (96, 96, 3) Box(0, 255, (96, 96, 3), uint8)\n",
            "obs['velocity'] <class 'numpy.float64'>\n",
            "obs['on_track']: <class 'bool'>\n",
            "Action Sample:  [0.5328 0.8534 0.0941]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Env Demo**\n",
        "#@markdown Standard Gym Env (0.26.0 API)\n",
        "#@markdown Car Racing Demo\n",
        "\n",
        "# 0. create env object\n",
        "env = CarRacing()\n",
        "\n",
        "# 2. must reset before use\n",
        "obs = env.reset(seed=200)\n",
        "\n",
        "# 3. 2D positional action space [0,512]\n",
        "action = env.action_space.sample()\n",
        "\n",
        "# 4. Standard gym step method\n",
        "obs, reward, done, _ ,info = env.step(action)\n",
        "\n",
        "# prints and explains each dimension of the observation and action vectors\n",
        "with np.printoptions(precision=4, suppress=True, threshold=5):\n",
        "\n",
        "    print(\"obs['image'].shape:\", obs['image'].shape, \"Box(0, 255, (96, 96, 3), uint8)\")\n",
        "    print(\"obs['velocity']\", type(obs['velocity']))\n",
        "    print(\"obs['on_track']:\", type(obs['on_track']))\n",
        "    print(\"Action Sample: \", action)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "PsPVkYnVXKhZ"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Dataset**\n",
        "#@markdown\n",
        "#@markdown Defines `CarRacingDataset` and helper functions\n",
        "#@markdown\n",
        "#@markdown The dataset class\n",
        "#@markdown - Load data from a zarr storage\n",
        "#@markdown - Normalizes each dimension of non-images and actions to [-1,1]\n",
        "#@markdown - Returns\n",
        "#@markdown  - All possible segments with length `pred_horizon`\n",
        "#@markdown  - Pads the beginning and the end of each episode with repetition\n",
        "#@markdown  - key `image`: shape (obs_hoirzon, 3, 96, 96)\n",
        "#@markdown  - key `velocity`: shape (obs_horizon, 1)\n",
        "#@markdown  - key `track`: shape (obs_horizon, 1)\n",
        "#@markdown  - key `action`: shape (pred_horizon, 3) \n",
        "\n",
        "def create_sample_indices(\n",
        "        episode_ends:np.ndarray, sequence_length:int, \n",
        "        pad_before: int=0, pad_after: int=0):\n",
        "    indices = list()\n",
        "    for i in range(len(episode_ends)):\n",
        "        start_idx = 0\n",
        "        if i > 0:\n",
        "            start_idx = episode_ends[i-1]\n",
        "        end_idx = episode_ends[i]\n",
        "        episode_length = end_idx - start_idx\n",
        "        \n",
        "        min_start = -pad_before\n",
        "        max_start = episode_length - sequence_length + pad_after\n",
        "        \n",
        "        # range stops one idx before end\n",
        "        for idx in range(min_start, max_start+1):\n",
        "            buffer_start_idx = max(idx, 0) + start_idx\n",
        "            buffer_end_idx = min(idx+sequence_length, episode_length) + start_idx\n",
        "            start_offset = buffer_start_idx - (idx+start_idx)\n",
        "            end_offset = (idx+sequence_length+start_idx) - buffer_end_idx\n",
        "            sample_start_idx = 0 + start_offset\n",
        "            sample_end_idx = sequence_length - end_offset\n",
        "            indices.append([\n",
        "                buffer_start_idx, buffer_end_idx, \n",
        "                sample_start_idx, sample_end_idx])\n",
        "    indices = np.array(indices)\n",
        "    return indices\n",
        "\n",
        "\n",
        "def sample_sequence(train_data, sequence_length,\n",
        "                    buffer_start_idx, buffer_end_idx, \n",
        "                    sample_start_idx, sample_end_idx):\n",
        "    result = dict()\n",
        "    for key, input_arr in train_data.items():\n",
        "        sample = input_arr[buffer_start_idx:buffer_end_idx]\n",
        "        data = sample\n",
        "        if (sample_start_idx > 0) or (sample_end_idx < sequence_length):\n",
        "            data = np.zeros(\n",
        "                shape=(sequence_length,) + input_arr.shape[1:],\n",
        "                dtype=input_arr.dtype)\n",
        "            if sample_start_idx > 0:\n",
        "                data[:sample_start_idx] = sample[0]\n",
        "            if sample_end_idx < sequence_length:\n",
        "                data[sample_end_idx:] = sample[-1]\n",
        "            data[sample_start_idx:sample_end_idx] = sample\n",
        "        result[key] = data\n",
        "    return result\n",
        "\n",
        "# normalize data\n",
        "def get_data_stats(data):\n",
        "    data = data.reshape(-1,data.shape[-1])\n",
        "    stats = {\n",
        "        'min': np.min(data, axis=0),\n",
        "        'max': np.max(data, axis=0)\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "def normalize_data(data, stats):\n",
        "    # nomalize to [0,1]\n",
        "    ndata = (data - stats['min']) / (stats['max'] - stats['min'])\n",
        "    # normalize to [-1, 1]\n",
        "    ndata = ndata * 2 - 1\n",
        "    return ndata\n",
        "\n",
        "def unnormalize_data(ndata, stats):\n",
        "    ndata = (ndata + 1) / 2\n",
        "    data = ndata * (stats['max'] - stats['min']) + stats['min']\n",
        "    return data\n",
        "\n",
        "# dataset\n",
        "class CarRacingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, \n",
        "                 dataset_path: str,\n",
        "                 pred_horizon: int, \n",
        "                 obs_horizon: int, \n",
        "                 action_horizon: int):\n",
        "        \n",
        "        # read from zarr dataset\n",
        "        dataset_root = zarr.open(dataset_path, 'r')\n",
        "        \n",
        "        # float32, [0,1], (N,96,96,3)\n",
        "        train_image_data = dataset_root['data']['img'][:]\n",
        "        train_image_data = np.moveaxis(train_image_data, -1,1)\n",
        "        # (N,3,96,96)\n",
        "\n",
        "        # (N, D)\n",
        "        train_data = {\n",
        "            # velocity of var\n",
        "            'car_vel': dataset_root['data']['velocity'][:], # (T,1)\n",
        "            # Classifier value if on or off the track\n",
        "            'track': dataset_root['data']['on_track'][:], # (T,1)\n",
        "            'action': dataset_root['data']['action'][:] #(T,3)\n",
        "        }\n",
        "        episode_ends = dataset_root['meta']['episode_ends'][:]\n",
        "        \n",
        "        # compute start and end of each state-action sequence\n",
        "        # also handles padding\n",
        "        indices = create_sample_indices(\n",
        "            episode_ends=episode_ends,\n",
        "            sequence_length=pred_horizon,\n",
        "            pad_before=obs_horizon-1,\n",
        "            pad_after=action_horizon-1)\n",
        "\n",
        "        # compute statistics and normalized data to [-1,1]\n",
        "        stats = dict()\n",
        "        normalized_train_data = dict()\n",
        "        for key, data in train_data.items():\n",
        "            stats[key] = get_data_stats(data)\n",
        "            normalized_train_data[key] = normalize_data(data, stats[key])\n",
        "        \n",
        "        # images are already normalized\n",
        "        normalized_train_data['image'] = train_image_data\n",
        "\n",
        "        self.indices = indices\n",
        "        self.stats = stats\n",
        "        self.normalized_train_data = normalized_train_data\n",
        "        self.pred_horizon = pred_horizon\n",
        "        self.action_horizon = action_horizon\n",
        "        self.obs_horizon = obs_horizon\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # get the start/end indices for this datapoint\n",
        "        buffer_start_idx, buffer_end_idx, \\\n",
        "            sample_start_idx, sample_end_idx = self.indices[idx]\n",
        "\n",
        "        # get nomralized data using these indices\n",
        "        nsample = sample_sequence(\n",
        "            train_data=self.normalized_train_data,\n",
        "            sequence_length=self.pred_horizon,\n",
        "            buffer_start_idx=buffer_start_idx,\n",
        "            buffer_end_idx=buffer_end_idx,\n",
        "            sample_start_idx=sample_start_idx,\n",
        "            sample_end_idx=sample_end_idx\n",
        "        )\n",
        "\n",
        "        # discard unused observations\n",
        "        nsample['image'] = nsample['image'][:self.obs_horizon,:]\n",
        "        nsample['car_vel'] = nsample['car_vel'][:self.obs_horizon,:]\n",
        "        nsample['track'] = nsample['track'][:self.obs_horizon,:]\n",
        "        return nsample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdV8ITzY6f23",
        "outputId": "274621b2-e82d-442f-eb90-de7544ddaedb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualizing Batch and Data structure\n",
            "\n",
            "--> Key: car_vel\n",
            "Shape: (128, 3)\n",
            "torch.Size([128, 3, 1])\n",
            "\n",
            "--> Key: track\n",
            "Shape: (128, 3)\n",
            "torch.Size([128, 3, 1])\n",
            "\n",
            "--> Key: action\n",
            "Shape: (128, 8)\n",
            "torch.Size([128, 8, 3])\n",
            "\n",
            "--> Key: image\n",
            "Shape: (128, 3)\n",
            "torch.Size([128, 3, 3, 96, 96])\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Dataset Demo**\n",
        "#@markdown A dataset is loaded and later used for training.\n",
        "#@markdown ***Note:*** If data is not available on your drive, \n",
        "#@markdown it is fetched from our Google Drive and saved during this runtime (temporary).\n",
        "#@markdown For code which generated dataset see: \n",
        "#@markdown [Shared Autonomy and Risk negtioation](https://github.com/rafaelsoStanford/SharedAutonomy_RiskNegotiation/tree/main)\n",
        "\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/ActionPrediction/data/multipleDrivingBehaviours.zarr.zip'\n",
        "# download demonstration data from Google Drive if not available\n",
        "if not os.path.isfile(dataset_path):\n",
        "    #Locally saves the file (temporary; deleted after runtime)\n",
        "    print(\"Downloading File from Google drive\")\n",
        "    id = \"1wGyKMi0YK_URUOX8PtpRkmM0pYAMyBsS\"\n",
        "    dataset_path = 'multipleDrivingBehaviours.zarr.zip'\n",
        "    gdown.download(id=id, output=dataset_path, quiet=False)\n",
        "zarr_array = zarr.open(dataset_path, mode='r')\n",
        "\n",
        "# parameters\n",
        "pred_horizon = 8\n",
        "obs_horizon = 3\n",
        "action_horizon = 2\n",
        "\n",
        "# create dataset from file\n",
        "dataset = CarRacingDataset(\n",
        "    dataset_path=dataset_path,\n",
        "    pred_horizon=pred_horizon,\n",
        "    obs_horizon=obs_horizon,\n",
        "    action_horizon=action_horizon\n",
        ")\n",
        "# save training data statistics (min, max) for each dim\n",
        "stats = dataset.stats\n",
        "#print(dataset.normalized_train_data.keys())\n",
        "#print(list(dataset.normalized_train_data.keys())[0], \": \", dataset.normalized_train_data[list(dataset.normalized_train_data.keys())[0]].shape)\n",
        "#print(list(dataset.normalized_train_data.keys())[1], \": \", dataset.normalized_train_data[list(dataset.normalized_train_data.keys())[1]].shape)\n",
        "#print(list(dataset.normalized_train_data.keys())[2], \": \", dataset.normalized_train_data[list(dataset.normalized_train_data.keys())[2]].shape)\n",
        "\n",
        "# create dataloader\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=4,\n",
        "    shuffle=True,\n",
        "    # accelerate cpu-gpu transfer\n",
        "    pin_memory=True, \n",
        "    # don't kill worker process afte each epoch\n",
        "    persistent_workers=True \n",
        ")\n",
        "\n",
        "# visualize data in batch\n",
        "batch = next(iter(dataloader))\n",
        "\n",
        "\n",
        "print(\"Visualizing Batch and Data structure\")\n",
        "for key, value in batch.items():\n",
        "        print()\n",
        "        print(f'--> Key: {key}')\n",
        "        print(f'Shape: ({len(value)}, {len(value[0])})')\n",
        "        print(value.shape)\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "3ljHno7z8uyY"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Vision Encoder**\n",
        "#@markdown\n",
        "#@markdown Defines helper functions:\n",
        "#@markdown - `get_resnet` to initialize standard ResNet vision encoder\n",
        "#@markdown - `replace_bn_with_gn` to replace all BatchNorm layers with GroupNorm\n",
        "\n",
        "def get_resnet(name:str, weights=None, **kwargs) -> nn.Module:\n",
        "    \"\"\"\n",
        "    name: resnet18, resnet34, resnet50\n",
        "    weights: \"IMAGENET1K_V1\", None\n",
        "    \"\"\"\n",
        "    # Use standard ResNet implementation from torchvision\n",
        "    func = getattr(torchvision.models, name)\n",
        "    resnet = func(weights=weights, **kwargs)\n",
        "\n",
        "    # remove the final fully connected layer\n",
        "    # for resnet18, the output dim should be 512\n",
        "    resnet.fc = torch.nn.Identity()\n",
        "    return resnet\n",
        "\n",
        "\n",
        "def replace_submodules(\n",
        "        root_module: nn.Module, \n",
        "        predicate: Callable[[nn.Module], bool], \n",
        "        func: Callable[[nn.Module], nn.Module]) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Replace all submodules selected by the predicate with\n",
        "    the output of func.\n",
        "\n",
        "    predicate: Return true if the module is to be replaced.\n",
        "    func: Return new module to use.\n",
        "    \"\"\"\n",
        "    if predicate(root_module):\n",
        "        return func(root_module)\n",
        "\n",
        "    bn_list = [k.split('.') for k, m \n",
        "        in root_module.named_modules(remove_duplicate=True) \n",
        "        if predicate(m)]\n",
        "    for *parent, k in bn_list:\n",
        "        parent_module = root_module\n",
        "        if len(parent) > 0:\n",
        "            parent_module = root_module.get_submodule('.'.join(parent))\n",
        "        if isinstance(parent_module, nn.Sequential):\n",
        "            src_module = parent_module[int(k)]\n",
        "        else:\n",
        "            src_module = getattr(parent_module, k)\n",
        "        tgt_module = func(src_module)\n",
        "        if isinstance(parent_module, nn.Sequential):\n",
        "            parent_module[int(k)] = tgt_module\n",
        "        else:\n",
        "            setattr(parent_module, k, tgt_module)\n",
        "    # verify that all modules are replaced\n",
        "    bn_list = [k.split('.') for k, m \n",
        "        in root_module.named_modules(remove_duplicate=True) \n",
        "        if predicate(m)]\n",
        "    assert len(bn_list) == 0\n",
        "    return root_module\n",
        "\n",
        "def replace_bn_with_gn(\n",
        "    root_module: nn.Module, \n",
        "    features_per_group: int=16) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Relace all BatchNorm layers with GroupNorm.\n",
        "    \"\"\"\n",
        "    replace_submodules(\n",
        "        root_module=root_module,\n",
        "        predicate=lambda x: isinstance(x, nn.BatchNorm2d),\n",
        "        func=lambda x: nn.GroupNorm(\n",
        "            num_groups=x.num_features//features_per_group, \n",
        "            num_channels=x.num_features)\n",
        "    )\n",
        "    return root_module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "RjIVXTd6c4PU"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Network**\n",
        "#@markdown\n",
        "#@markdown Defines a 1D UNet architecture `ConditionalUnet1D`\n",
        "#@markdown as the noies prediction network\n",
        "#@markdown\n",
        "#@markdown Components\n",
        "#@markdown - `SinusoidalPosEmb` Positional encoding for the diffusion iteration k\n",
        "#@markdown - `Downsample1d` Strided convolution to reduce temporal resolution\n",
        "#@markdown - `Upsample1d` Transposed convolution to increase temporal resolution\n",
        "#@markdown - `Conv1dBlock` Conv1d --> GroupNorm --> Mish\n",
        "#@markdown - `ConditionalResidualBlock1D` Takes two inputs `x` and `cond`. \\\n",
        "#@markdown `x` is passed through 2 `Conv1dBlock` stacked together with residual connection. \n",
        "#@markdown `cond` is applied to `x` with [FiLM](https://arxiv.org/abs/1709.07871) conditioning.\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "\n",
        "class Downsample1d(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class Upsample1d(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Conv1dBlock(nn.Module):\n",
        "    '''\n",
        "        Conv1d --> GroupNorm --> Mish\n",
        "    '''\n",
        "\n",
        "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
        "            nn.GroupNorm(n_groups, out_channels),\n",
        "            nn.Mish(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class ConditionalResidualBlock1D(nn.Module):\n",
        "    def __init__(self, \n",
        "            in_channels, \n",
        "            out_channels, \n",
        "            cond_dim,\n",
        "            kernel_size=3,\n",
        "            n_groups=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Conv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups),\n",
        "            Conv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups),\n",
        "        ])\n",
        "\n",
        "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
        "        # predicts per-channel scale and bias\n",
        "        cond_channels = out_channels * 2\n",
        "        self.out_channels = out_channels\n",
        "        self.cond_encoder = nn.Sequential(\n",
        "            nn.Mish(),\n",
        "            nn.Linear(cond_dim, cond_channels),\n",
        "            nn.Unflatten(-1, (-1, 1))\n",
        "        )\n",
        "\n",
        "        # make sure dimensions compatible\n",
        "        self.residual_conv = nn.Conv1d(in_channels, out_channels, 1) \\\n",
        "            if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        '''\n",
        "            x : [ batch_size x in_channels x horizon ]\n",
        "            cond : [ batch_size x cond_dim]\n",
        "\n",
        "            returns:\n",
        "            out : [ batch_size x out_channels x horizon ]\n",
        "        '''\n",
        "        out = self.blocks[0](x)\n",
        "        embed = self.cond_encoder(cond)\n",
        "\n",
        "        embed = embed.reshape(\n",
        "            embed.shape[0], 2, self.out_channels, 1)\n",
        "        scale = embed[:,0,...]\n",
        "        bias = embed[:,1,...]\n",
        "        out = scale * out + bias\n",
        "\n",
        "        out = self.blocks[1](out)\n",
        "        out = out + self.residual_conv(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ConditionalUnet1D(nn.Module):\n",
        "    def __init__(self, \n",
        "        input_dim,\n",
        "        global_cond_dim,\n",
        "        diffusion_step_embed_dim=256,\n",
        "        down_dims=[256,512,1024],\n",
        "        kernel_size=5,\n",
        "        n_groups=8\n",
        "        ):\n",
        "        \"\"\"\n",
        "        input_dim: Dim of actions.\n",
        "        global_cond_dim: Dim of global conditioning applied with FiLM \n",
        "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
        "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
        "        down_dims: Channel size for each UNet level. \n",
        "          The length of this array determines numebr of levels.\n",
        "        kernel_size: Conv kernel size\n",
        "        n_groups: Number of groups for GroupNorm\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        all_dims = [input_dim] + list(down_dims)\n",
        "        start_dim = down_dims[0]\n",
        "\n",
        "        dsed = diffusion_step_embed_dim\n",
        "        diffusion_step_encoder = nn.Sequential(\n",
        "            SinusoidalPosEmb(dsed),\n",
        "            nn.Linear(dsed, dsed * 4),\n",
        "            nn.Mish(),\n",
        "            nn.Linear(dsed * 4, dsed),\n",
        "        )\n",
        "        cond_dim = dsed + global_cond_dim\n",
        "\n",
        "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
        "        mid_dim = all_dims[-1]\n",
        "        self.mid_modules = nn.ModuleList([\n",
        "            ConditionalResidualBlock1D(\n",
        "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
        "                kernel_size=kernel_size, n_groups=n_groups\n",
        "            ),\n",
        "            ConditionalResidualBlock1D(\n",
        "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
        "                kernel_size=kernel_size, n_groups=n_groups\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "        down_modules = nn.ModuleList([])\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (len(in_out) - 1)\n",
        "            down_modules.append(nn.ModuleList([\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_in, dim_out, cond_dim=cond_dim, \n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_out, dim_out, cond_dim=cond_dim, \n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                Downsample1d(dim_out) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        up_modules = nn.ModuleList([])\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
        "            is_last = ind >= (len(in_out) - 1)\n",
        "            up_modules.append(nn.ModuleList([\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_out*2, dim_in, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_in, dim_in, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                Upsample1d(dim_in) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "        \n",
        "        final_conv = nn.Sequential(\n",
        "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
        "            nn.Conv1d(start_dim, input_dim, 1),\n",
        "        )\n",
        "\n",
        "        self.diffusion_step_encoder = diffusion_step_encoder\n",
        "        self.up_modules = up_modules\n",
        "        self.down_modules = down_modules\n",
        "        self.final_conv = final_conv\n",
        "\n",
        "        print(\"number of parameters: {:e}\".format(\n",
        "            sum(p.numel() for p in self.parameters()))\n",
        "        )\n",
        "\n",
        "    def forward(self, \n",
        "            sample: torch.Tensor, \n",
        "            timestep: Union[torch.Tensor, float, int], \n",
        "            global_cond=None):\n",
        "        \"\"\"\n",
        "        x: (B,T,input_dim)\n",
        "        timestep: (B,) or int, diffusion step\n",
        "        global_cond: (B,global_cond_dim)\n",
        "        output: (B,T,input_dim)\n",
        "        \"\"\"\n",
        "        # (B,T,C)\n",
        "        sample = sample.moveaxis(-1,-2)\n",
        "        # (B,C,T)\n",
        "\n",
        "        # 1. time\n",
        "        timesteps = timestep\n",
        "        if not torch.is_tensor(timesteps):\n",
        "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
        "            timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\n",
        "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
        "            timesteps = timesteps[None].to(sample.device)\n",
        "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
        "        timesteps = timesteps.expand(sample.shape[0])\n",
        "\n",
        "        global_feature = self.diffusion_step_encoder(timesteps)\n",
        "\n",
        "        if global_cond is not None:\n",
        "            global_feature = torch.cat([\n",
        "                global_feature, global_cond\n",
        "            ], axis=-1)\n",
        "        \n",
        "        x = sample\n",
        "        h = []\n",
        "        for idx, (resnet, resnet2, downsample) in enumerate(self.down_modules):\n",
        "            x = resnet(x, global_feature)\n",
        "            x = resnet2(x, global_feature)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        for mid_module in self.mid_modules:\n",
        "            x = mid_module(x, global_feature)\n",
        "\n",
        "        for idx, (resnet, resnet2, upsample) in enumerate(self.up_modules):\n",
        "            x = torch.cat((x, h.pop()), dim=1)\n",
        "            x = resnet(x, global_feature)\n",
        "            x = resnet2(x, global_feature)\n",
        "            x = upsample(x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        # (B,C,T)\n",
        "        x = x.moveaxis(-1,-2)\n",
        "        # (B,T,C)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO4xvJ__dAdv",
        "outputId": "4e61139b-60a6-4ac3-b5d0-f99d9d80ca03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 8.727476e+07\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Network Demo**\n",
        "\n",
        "# construct ResNet18 encoder\n",
        "# if you have multiple camera views, use seperate encoder weights for each view.\n",
        "vision_encoder = get_resnet('resnet18')\n",
        "\n",
        "# IMPORTANT!\n",
        "# replace all BatchNorm with GroupNorm to work with EMA\n",
        "# performance will tank if you forget to do this!\n",
        "vision_encoder = replace_bn_with_gn(vision_encoder)\n",
        "\n",
        "\n",
        "## Dimensions of Features ## \n",
        "\n",
        "# ResNet18 has output dim of 512\n",
        "vision_feature_dim = 512\n",
        "# Car Velocity is 1 dimensional\n",
        "lowdim_obs_dim = 1\n",
        "# observation feature has 514 dims in total per step\n",
        "obs_dim = vision_feature_dim + lowdim_obs_dim\n",
        "# Action space is 3 dimensional\n",
        "action_dim = 3\n",
        "\n",
        "# create network object\n",
        "noise_pred_net = ConditionalUnet1D(\n",
        "    input_dim=action_dim,\n",
        "    global_cond_dim=obs_dim*obs_horizon\n",
        ")\n",
        "\n",
        "# the final arch has 2 parts\n",
        "nets = nn.ModuleDict({\n",
        "    'vision_encoder': vision_encoder,\n",
        "    'noise_pred_net': noise_pred_net\n",
        "})\n",
        "\n",
        "# demo\n",
        "with torch.no_grad():\n",
        "    # example inputs\n",
        "    image = torch.zeros((1, obs_horizon,3,96,96))\n",
        "    agent_vel = torch.zeros((1, obs_horizon, 1))\n",
        "    # vision encoder\n",
        "    image_features = nets['vision_encoder'](\n",
        "        image.flatten(end_dim=1))\n",
        "    # (2,512)\n",
        "    image_features = image_features.reshape(*image.shape[:2],-1)\n",
        "    # (1,2,512)\n",
        "    obs = torch.cat([image_features, agent_vel],dim=-1)\n",
        "    # (1,2,514)\n",
        "\n",
        "    noised_action = torch.randn((1, pred_horizon, action_dim))\n",
        "    diffusion_iter = torch.zeros((1,))\n",
        "\n",
        "    # the noise prediction network\n",
        "    # takes noisy action, diffusion iteration and observation as input\n",
        "    # predicts the noise added to action\n",
        "    noise = nets['noise_pred_net'](\n",
        "        sample=noised_action, \n",
        "        timestep=diffusion_iter,\n",
        "        global_cond=obs.flatten(start_dim=1))\n",
        "\n",
        "    # illustration of removing noise \n",
        "    # the actual noise removal is performed by NoiseScheduler \n",
        "    # and is dependent on the diffusion noise schedule\n",
        "    denoised_action = noised_action - noise\n",
        "\n",
        "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
        "num_diffusion_iters = 100\n",
        "noise_scheduler = DDPMScheduler(\n",
        "    num_train_timesteps=num_diffusion_iters,\n",
        "    # the choise of beta schedule has big impact on performance\n",
        "    # we found squared cosine works the best\n",
        "    beta_schedule='squaredcos_cap_v2',\n",
        "    # clip output to [-1,1] to improve stability\n",
        "    clip_sample=True,\n",
        "    # our network predicts noise (instead of denoised action)\n",
        "    prediction_type='epsilon'\n",
        ")\n",
        "\n",
        "# device transfer\n",
        "device = torch.device('cuda')\n",
        "_ = nets.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "1cd6be86c6464ff08af6f876bc01ccc5",
            "bc0827d62c504772ac7b9f4b30369fc5",
            "b00a6a4f3cd04002a49aaba5fe3cb5db",
            "3a7d7092190640e0b79c9efcb328b918",
            "669c762f063b4bae9c35878641af7b66",
            "9f81e3ee8c2d44ebad9761b68c7762ca",
            "a73aa1b45c214e5080547ed3889b0c63",
            "15e653d49f0e430fa0c5c5cc4576ecc2",
            "cac76763e3b04f7b9f8a93d2b8048937",
            "315ea3f508c84e2ab36c51f9c883e742",
            "e2825a9b21e5474bb8380461c553d943",
            "0db62508d300470f977a3235e73390f6",
            "cc015557e72049c181ec17b4a8105a09",
            "5ed9a9c45bdd4da5ba1ced03575b53f0",
            "6a6dd7c7c38a4b38a3461f41d67ae485",
            "82ab08c8196d421a86d96976c6e87cf3",
            "aedbb47d4fda4e3f9c96a223237ecb3e",
            "68ea6fce5e4d4a968d9bc093520a30b4",
            "ac3c17478eb44f0d825a69082b78b3a5",
            "8a297f9c1a32497890b8b56c132ddd02",
            "027852f5fa194e57a5c6b8068c4449b4",
            "a489d1aca966474ba3a986957b38ca3e",
            "d1f010b537eb4b2a9737d7c53961ffa8",
            "abe1bfb0943c46599111e8ccfa8cd3ac",
            "36034e74a07b46e6a332983398f27b06",
            "91985f00ed7d430ea39d4b814eb8d87a",
            "45fe55b58d214515b6c603e3fed0154e",
            "869288d74d124fbdad4a559a620e84eb",
            "c2429cc580214725a54cc651521651d8",
            "0194ef3e4fd4468d97b75859238a6f5b",
            "63130763bb4f47e39e94ae14a97a2517",
            "fbbd7467dd1a456c823d1e0bbb2d12b5",
            "6106f848cc984e0dbe4f603fb525a9ff",
            "fc7655f0c57d4de0a8fedddf36de3c43",
            "d9d008253fc74715b0359e8f4b4ebdaf",
            "4f1324e79f1943aa9e965261f4c569a8",
            "86abaff9b9c24beab7867be13fe5ec7c",
            "f2d83b3e566944d79032915026f092cd",
            "dbb42ba2ee4241b99713cdff661740c7",
            "22f7fae5e2de460285619dc378cb974c",
            "a9e46f84d0c340d58763d0a05df7adf6",
            "d63b5a27f04949fe8ea4eb1f5df02a39",
            "6523ab0d9ece4c21ae892b756ed87656",
            "5c927c636d3c44fa9fc18fba3d55fbd8",
            "b28c51fbed2b454ab3ed3a1247c40a62",
            "c7d772aa27a5405889311e09ced27cf3",
            "37f0600ede7840568800721b47da93b0",
            "311826250fe744f38484de3df5d08973",
            "3ee1eed908ba4f69a19ef8c746b7a696",
            "6aa8924300954ee59a290c1a22f05885",
            "5c617c1c4753487d8c457db9a0c8eb6f",
            "68ffe336ede64cf082b7491d4447fba0",
            "744d7fe0ff494e3bb45e721b48c27278",
            "026c900655924254905f1fc8fe3c28c0",
            "183307b84412453b98c47dbc7866f180"
          ]
        },
        "id": "GGzBZc5xdwIK",
        "outputId": "374da20a-5b25-4945-a1e7-6a9138b5ad30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cd6be86c6464ff08af6f876bc01ccc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batch:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0db62508d300470f977a3235e73390f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batch:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1f010b537eb4b2a9737d7c53961ffa8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batch:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc7655f0c57d4de0a8fedddf36de3c43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batch:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b28c51fbed2b454ab3ed3a1247c40a62"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ### **Training**\n",
        "#@markdown\n",
        "#@markdown Takes about 2.5 hours. If you don't want to wait, skip to the next cell\n",
        "#@markdown to load pre-trained weights\n",
        "\n",
        "num_epochs = 100\n",
        "# Build training checkpoints for reloading\n",
        "# If used make sure you have the desired checkpoints available:\n",
        "createCheckpoints = True\n",
        "if createCheckpoints:\n",
        "  checkpoint_dir = \"/content/drive/MyDrive/ActionPrediction/checkpoints\"\n",
        "  checkpoint_counter = 0\n",
        "  checkpoint_frequency = 10  # save model every 10 epochs\n",
        "\n",
        "min_loss = float('inf')\n",
        "# Exponential Moving Average\n",
        "# accelerates training and improves stability\n",
        "# holds a copy of the model weights\n",
        "ema = EMAModel(\n",
        "    model=nets,\n",
        "    power=0.75)\n",
        "\n",
        "# Standard ADAM optimizer\n",
        "# Note that EMA parametesr are not optimized\n",
        "optimizer = torch.optim.AdamW(\n",
        "    params=nets.parameters(), \n",
        "    lr=1e-4, weight_decay=1e-6)\n",
        "\n",
        "# Cosine LR schedule with linear warmup\n",
        "lr_scheduler = get_scheduler(\n",
        "    name='cosine',\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=500,\n",
        "    num_training_steps=len(dataloader) * num_epochs\n",
        ")\n",
        "\n",
        "\n",
        "with tqdm(range(num_epochs), desc='Epoch') as tglobal:\n",
        "    # epoch loop\n",
        "    for epoch_idx in tglobal:\n",
        "        epoch_loss = list()\n",
        "        # batch loop\n",
        "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
        "            for nbatch in tepoch:\n",
        "                # data normalized in dataset\n",
        "                # device transfer\n",
        "                nimage = nbatch['image'][:,:obs_horizon].to(device)\n",
        "                ncar_vel = nbatch['car_vel'][:,:obs_horizon].to(device)\n",
        "                naction = nbatch['action'].to(device)\n",
        "                B = ncar_vel.shape[0]\n",
        "\n",
        "                # encoder vision features\n",
        "                image_features = nets['vision_encoder'](\n",
        "                    nimage.flatten(end_dim=1))\n",
        "                image_features = image_features.reshape(\n",
        "                    *nimage.shape[:2],-1)\n",
        "                # (B,obs_horizon,D)\n",
        "\n",
        "                # concatenate vision feature and low-dim obs\n",
        "                obs_features = torch.cat([image_features, ncar_vel], dim=-1)\n",
        "                obs_cond = obs_features.flatten(start_dim=1)\n",
        "                # (B, obs_horizon * obs_dim)\n",
        "\n",
        "                # sample noise to add to actions\n",
        "                noise = torch.randn(naction.shape, device=device)\n",
        "\n",
        "                # sample a diffusion iteration for each data point\n",
        "                timesteps = torch.randint(\n",
        "                    0, noise_scheduler.config.num_train_timesteps, \n",
        "                    (B,), device=device\n",
        "                ).long()\n",
        "\n",
        "                # add noise to the clean images according to the noise magnitude at each diffusion iteration\n",
        "                # (this is the forward diffusion process)\n",
        "                noisy_actions = noise_scheduler.add_noise(\n",
        "                    naction, noise, timesteps)\n",
        "                \n",
        "#                print(naction.shape)\n",
        "#                print(noisy_actions.shape)\n",
        "                \n",
        "                # predict the noise residual\n",
        "                noise_pred = noise_pred_net(\n",
        "                    noisy_actions, timesteps, global_cond=obs_cond)\n",
        "                \n",
        "                # L2 loss\n",
        "                loss = nn.functional.mse_loss(noise_pred, noise)\n",
        "\n",
        "                # optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                # step lr scheduler every batch\n",
        "                # this is different from standard pytorch behavior\n",
        "                lr_scheduler.step()\n",
        "\n",
        "                # update Exponential Moving Average of the model weights\n",
        "                ema.step(nets)\n",
        "\n",
        "                # logging\n",
        "                loss_cpu = loss.item()\n",
        "                epoch_loss.append(loss_cpu)\n",
        "                tepoch.set_postfix(loss=loss_cpu)\n",
        "        tglobal.set_postfix(loss=np.mean(epoch_loss))\n",
        "\n",
        "        if epoch_idx > 0 and epoch_idx % checkpoint_frequency == 0 and createCheckpoints==True:\n",
        "            # compute mean epoch loss\n",
        "            mean_epoch_loss = np.mean(epoch_loss)\n",
        "            # save model if mean epoch loss is smaller than the loss after the previous checkpoint\n",
        "            if mean_epoch_loss < min_loss:\n",
        "                min_loss = mean_epoch_loss\n",
        "                checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_Epoch{epoch_idx}.pt\")\n",
        "                torch.save(ema.averaged_model.state_dict(), checkpoint_path)\n",
        "                checkpoint_counter += 1\n",
        "                print(f\"Model saved at epoch {epoch_idx}\")\n",
        "\n",
        "\n",
        "# Weights of the EMA model\n",
        "# is used for inference\n",
        "ema_net = ema.averaged_model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY0q8DZLfLI1"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Loading Pretrained Checkpoint**\n",
        "#@markdown Set `load_pretrained = True` to load pretrained weights.\n",
        "\n",
        "load_pretrained = False\n",
        "checkpoint_num = 90\n",
        "ema_net = nets\n",
        "\n",
        "if load_pretrained:\n",
        "  ckpt_path = f\"/content/drive/MyDrive/checkpoints/checkpoint_Epoch{checkpoint_num}.pt\"\n",
        "\n",
        "  state_dict = torch.load(ckpt_path, map_location='cuda')\n",
        "  ema_net.load_state_dict(state_dict)\n",
        "  print('Pretrained weights loaded.')\n",
        "else:\n",
        "  print(\"Skipped pretrained weight loading.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_9y3ihZVeIrV"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Inference**\n",
        "\n",
        "# limit enviornment interaction to 200 steps before termination\n",
        "max_steps = 200\n",
        "env = CarRacing(render_mode='state_pixels')\n",
        "\n",
        "# get first observation\n",
        "observation = env.reset(seed = 7000)\n",
        "observation = observation[0]\n",
        "\n",
        "# keep a queue lenght of observations horizon\n",
        "obs_deque = collections.deque(\n",
        "    [observation] * obs_horizon, maxlen=obs_horizon)\n",
        "\n",
        "# save visualization and rewards\n",
        "imgs = [env.render()]\n",
        "rewards = list()\n",
        "done = False\n",
        "step_idx = 0\n",
        "\n",
        "\n",
        "with tqdm(total=max_steps, desc=\"Eval CarRacingImageEnv\") as pbar:\n",
        "    while not done:\n",
        "        B = 1\n",
        "        # stack the last obs_horizon number of observations\n",
        "        images = np.stack(x['image'] for x in obs_deque)\n",
        "        images = np.moveaxis(images, -1,1)\n",
        "        car_vel =  np.stack(x['velocity'] for x in obs_deque)\n",
        "        track_flag = np.stack(x['on_track'] for x in obs_deque)\n",
        "        # normalize observation\n",
        "        ncar_vels = normalize_data(car_vel, stats=stats['car_vel'])\n",
        "        # images are already normalized to [0,1]\n",
        "        nimages = images\n",
        "\n",
        "        # device transfer\n",
        "        nimages = torch.from_numpy(nimages).to(device, dtype=torch.float32)\n",
        "        # (2,3,96,96)\n",
        "        ncar_vels = torch.from_numpy(ncar_vels).to(device, dtype=torch.float32)\n",
        "        # (2,1)\n",
        "        ncar_vels = ncar_vels.unsqueeze(-1)\n",
        "\n",
        "\n",
        "        # infer action\n",
        "        with torch.no_grad():\n",
        "            # get image features\n",
        "            image_features = ema_net['vision_encoder'](nimages)\n",
        "            # (2,512)\n",
        "            # concat with low-dim observations\n",
        "            obs_features = torch.cat([image_features, ncar_vels], dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "            # reshape observation to (B,obs_horizon*obs_dim)\n",
        "            obs_cond = obs_features.unsqueeze(0).flatten(start_dim=1)\n",
        "\n",
        "            # initialize action from Guassian noise\n",
        "            noisy_action = torch.randn(\n",
        "                (B, pred_horizon, action_dim), device=device)\n",
        "            naction = noisy_action\n",
        "            \n",
        "            #print(noisy_action.shape)\n",
        "            \n",
        "\n",
        "            # init scheduler\n",
        "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
        "\n",
        "            for k in noise_scheduler.timesteps:\n",
        "                # predict noise\n",
        "                noise_pred = ema_net['noise_pred_net'](\n",
        "                    sample=naction, \n",
        "                    timestep=k,\n",
        "                    global_cond=obs_cond\n",
        "                )\n",
        "\n",
        "                # inverse diffusion step (remove noise)\n",
        "                naction = noise_scheduler.step(\n",
        "                    model_output=noise_pred,\n",
        "                    timestep=k,\n",
        "                    sample=naction\n",
        "                ).prev_sample\n",
        "\n",
        "        # unnormalize action\n",
        "        naction = naction.detach().to('cpu').numpy()\n",
        "        # (B, pred_horizon, action_dim)\n",
        "        naction = naction[0]\n",
        "        action_pred = unnormalize_data(naction, stats=stats['action'])\n",
        "\n",
        "        # only take action_horizon number of actions\n",
        "        start = obs_horizon - 1\n",
        "        end = start + action_horizon\n",
        "        action = action_pred[start:end,:]\n",
        "        # (action_horizon, action_dim)\n",
        "\n",
        "        # execute action_horizon number of steps\n",
        "        # without replanning\n",
        "        for i in range(len(action)):\n",
        "            # stepping env\n",
        "            obs, reward, done, _ , info = env.step(action[i])\n",
        "            # save observations\n",
        "            obs_deque.append(obs)\n",
        "            # and reward/vis\n",
        "            rewards.append(reward)\n",
        "            imgs.append(env.render())\n",
        "\n",
        "            # update progress bar\n",
        "            step_idx += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix(reward=reward)\n",
        "            if step_idx > max_steps:\n",
        "                done = True\n",
        "            if done:\n",
        "                break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xl38a-ubeU5-"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Visualize**\n",
        "# visualize\n",
        "from IPython.display import Video\n",
        "vwrite('vis.mp4', imgs)\n",
        "Video('vis.mp4', embed=True, width=256, height=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5W9CywdhRzwl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1cd6be86c6464ff08af6f876bc01ccc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc0827d62c504772ac7b9f4b30369fc5",
              "IPY_MODEL_b00a6a4f3cd04002a49aaba5fe3cb5db",
              "IPY_MODEL_3a7d7092190640e0b79c9efcb328b918"
            ],
            "layout": "IPY_MODEL_669c762f063b4bae9c35878641af7b66"
          }
        },
        "bc0827d62c504772ac7b9f4b30369fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f81e3ee8c2d44ebad9761b68c7762ca",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a73aa1b45c214e5080547ed3889b0c63",
            "value": "Epoch:   3%"
          }
        },
        "b00a6a4f3cd04002a49aaba5fe3cb5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e653d49f0e430fa0c5c5cc4576ecc2",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cac76763e3b04f7b9f8a93d2b8048937",
            "value": 3
          }
        },
        "3a7d7092190640e0b79c9efcb328b918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_315ea3f508c84e2ab36c51f9c883e742",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e2825a9b21e5474bb8380461c553d943",
            "value": " 3/100 [00:29&lt;14:22,  8.89s/it, loss=0.883]"
          }
        },
        "669c762f063b4bae9c35878641af7b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f81e3ee8c2d44ebad9761b68c7762ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73aa1b45c214e5080547ed3889b0c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15e653d49f0e430fa0c5c5cc4576ecc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac76763e3b04f7b9f8a93d2b8048937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "315ea3f508c84e2ab36c51f9c883e742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2825a9b21e5474bb8380461c553d943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0db62508d300470f977a3235e73390f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc015557e72049c181ec17b4a8105a09",
              "IPY_MODEL_5ed9a9c45bdd4da5ba1ced03575b53f0",
              "IPY_MODEL_6a6dd7c7c38a4b38a3461f41d67ae485"
            ],
            "layout": "IPY_MODEL_82ab08c8196d421a86d96976c6e87cf3"
          }
        },
        "cc015557e72049c181ec17b4a8105a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aedbb47d4fda4e3f9c96a223237ecb3e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_68ea6fce5e4d4a968d9bc093520a30b4",
            "value": "Batch: 100%"
          }
        },
        "5ed9a9c45bdd4da5ba1ced03575b53f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac3c17478eb44f0d825a69082b78b3a5",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a297f9c1a32497890b8b56c132ddd02",
            "value": 16
          }
        },
        "6a6dd7c7c38a4b38a3461f41d67ae485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027852f5fa194e57a5c6b8068c4449b4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a489d1aca966474ba3a986957b38ca3e",
            "value": " 16/16 [00:14&lt;00:00,  2.56it/s, loss=1.04]"
          }
        },
        "82ab08c8196d421a86d96976c6e87cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "aedbb47d4fda4e3f9c96a223237ecb3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ea6fce5e4d4a968d9bc093520a30b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac3c17478eb44f0d825a69082b78b3a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a297f9c1a32497890b8b56c132ddd02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "027852f5fa194e57a5c6b8068c4449b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a489d1aca966474ba3a986957b38ca3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1f010b537eb4b2a9737d7c53961ffa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abe1bfb0943c46599111e8ccfa8cd3ac",
              "IPY_MODEL_36034e74a07b46e6a332983398f27b06",
              "IPY_MODEL_91985f00ed7d430ea39d4b814eb8d87a"
            ],
            "layout": "IPY_MODEL_45fe55b58d214515b6c603e3fed0154e"
          }
        },
        "abe1bfb0943c46599111e8ccfa8cd3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869288d74d124fbdad4a559a620e84eb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c2429cc580214725a54cc651521651d8",
            "value": "Batch: 100%"
          }
        },
        "36034e74a07b46e6a332983398f27b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0194ef3e4fd4468d97b75859238a6f5b",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63130763bb4f47e39e94ae14a97a2517",
            "value": 16
          }
        },
        "91985f00ed7d430ea39d4b814eb8d87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbbd7467dd1a456c823d1e0bbb2d12b5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6106f848cc984e0dbe4f603fb525a9ff",
            "value": " 16/16 [00:07&lt;00:00,  2.59it/s, loss=0.982]"
          }
        },
        "45fe55b58d214515b6c603e3fed0154e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "869288d74d124fbdad4a559a620e84eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2429cc580214725a54cc651521651d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0194ef3e4fd4468d97b75859238a6f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63130763bb4f47e39e94ae14a97a2517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbbd7467dd1a456c823d1e0bbb2d12b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6106f848cc984e0dbe4f603fb525a9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc7655f0c57d4de0a8fedddf36de3c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9d008253fc74715b0359e8f4b4ebdaf",
              "IPY_MODEL_4f1324e79f1943aa9e965261f4c569a8",
              "IPY_MODEL_86abaff9b9c24beab7867be13fe5ec7c"
            ],
            "layout": "IPY_MODEL_f2d83b3e566944d79032915026f092cd"
          }
        },
        "d9d008253fc74715b0359e8f4b4ebdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb42ba2ee4241b99713cdff661740c7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_22f7fae5e2de460285619dc378cb974c",
            "value": "Batch: 100%"
          }
        },
        "4f1324e79f1943aa9e965261f4c569a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9e46f84d0c340d58763d0a05df7adf6",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d63b5a27f04949fe8ea4eb1f5df02a39",
            "value": 16
          }
        },
        "86abaff9b9c24beab7867be13fe5ec7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6523ab0d9ece4c21ae892b756ed87656",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5c927c636d3c44fa9fc18fba3d55fbd8",
            "value": " 16/16 [00:07&lt;00:00,  2.61it/s, loss=0.741]"
          }
        },
        "f2d83b3e566944d79032915026f092cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "dbb42ba2ee4241b99713cdff661740c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f7fae5e2de460285619dc378cb974c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9e46f84d0c340d58763d0a05df7adf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63b5a27f04949fe8ea4eb1f5df02a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6523ab0d9ece4c21ae892b756ed87656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c927c636d3c44fa9fc18fba3d55fbd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b28c51fbed2b454ab3ed3a1247c40a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7d772aa27a5405889311e09ced27cf3",
              "IPY_MODEL_37f0600ede7840568800721b47da93b0",
              "IPY_MODEL_311826250fe744f38484de3df5d08973"
            ],
            "layout": "IPY_MODEL_3ee1eed908ba4f69a19ef8c746b7a696"
          }
        },
        "c7d772aa27a5405889311e09ced27cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aa8924300954ee59a290c1a22f05885",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5c617c1c4753487d8c457db9a0c8eb6f",
            "value": "Batch:  44%"
          }
        },
        "37f0600ede7840568800721b47da93b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ffe336ede64cf082b7491d4447fba0",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_744d7fe0ff494e3bb45e721b48c27278",
            "value": 7
          }
        },
        "311826250fe744f38484de3df5d08973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_026c900655924254905f1fc8fe3c28c0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_183307b84412453b98c47dbc7866f180",
            "value": " 7/16 [00:03&lt;00:03,  2.29it/s, loss=0.608]"
          }
        },
        "3ee1eed908ba4f69a19ef8c746b7a696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa8924300954ee59a290c1a22f05885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c617c1c4753487d8c457db9a0c8eb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68ffe336ede64cf082b7491d4447fba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "744d7fe0ff494e3bb45e721b48c27278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "026c900655924254905f1fc8fe3c28c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "183307b84412453b98c47dbc7866f180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}